{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0L0FSSXVMI2",
        "outputId": "dcf6d99b-906f-489e-f376-7b8689375d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "from pathlib import Path\n",
        "import random\n",
        "import time\n",
        "# Фіксуємо сид для відтворюваності\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = Path(\"./vegetables\")\n",
        "train_dir = data_root / \"train\"\n",
        "val_dir   = data_root / \"validation\"\n",
        "test_dir  = data_root / \"test\""
      ],
      "metadata": {
        "id": "m7VCkM4DVveR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "for split in [\"train\", \"validation\", \"test\"]:\n",
        "    ckpt_dir = Path(\"/content/vegetables\") / split / \".ipynb_checkpoints\"\n",
        "    if ckpt_dir.exists():\n",
        "        print(\"Видаляю\", ckpt_dir)\n",
        "        shutil.rmtree(ckpt_dir)\n",
        "    else:\n",
        "        print(\"Немає\", ckpt_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPB-dkALpIx7",
        "outputId": "ae428e3d-a341-4ff5-cd65-6beebf88c7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Видаляю /content/vegetables/train/.ipynb_checkpoints\n",
            "Видаляю /content/vegetables/validation/.ipynb_checkpoints\n",
            "Видаляю /content/vegetables/test/.ipynb_checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед подачею в нейронну мережу всі зображення були приведені до фіксованого розміру.\n",
        "Для тренувальної вибірки застосовувалась аугментація у вигляді випадкового горизонтального віддзеркалення (модель бачить помідор зліва, помідор справа,. Архітектура ResNet18 була попередньо натренована на великому датасеті ImageNet. У даній роботі було виконано перенесення знань: останній класифікаційний шар було замінено відповідно до кількості класів у задачі, після чого модель була донавчена на власному наборі зображень овочів."
      ],
      "metadata": {
        "id": "vIhLTutEna10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Трансформації для простої CNN\n",
        "simple_transform_train = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "simple_transform_eval = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Трансформації для ResNet18 (під ImageNet)\n",
        "resnet_transform_train = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "resnet_transform_eval = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "dzJWy3UqXo4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цей блок коду зчитує зображення з папок train/validation/test, автоматично створює мітки класів на основі назв директорій, застосовує необхідні перетворення, визначає кількість класів та формує DataLoader’и для пакетної подачі даних у нейронну мережу під час навчання, валідації та тестування."
      ],
      "metadata": {
        "id": "Ii7YhQ3SmFlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Для простої CNN\n",
        "train_dataset_simple = datasets.ImageFolder(train_dir, transform=simple_transform_train)\n",
        "val_dataset_simple   = datasets.ImageFolder(val_dir,   transform=simple_transform_eval)\n",
        "test_dataset_simple  = datasets.ImageFolder(test_dir,  transform=simple_transform_eval)\n",
        "\n",
        "print(\"Класи (порядок):\", train_dataset_simple.classes)\n",
        "num_classes = len(train_dataset_simple.classes)\n",
        "print(\"num_classes =\", num_classes)\n",
        "\n",
        "batch_size = 32 #скільки картинок модель обробляє за один крок навчання\n",
        "\n",
        "train_loader_simple = DataLoader(train_dataset_simple, batch_size=batch_size, shuffle=True)\n",
        "val_loader_simple   = DataLoader(val_dataset_simple,   batch_size=batch_size, shuffle=False)\n",
        "test_loader_simple  = DataLoader(test_dataset_simple,  batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "0JEGPjwzeuHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08daff5d-b36a-4b2c-9e02-9f577bee74eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Класи (порядок): ['Broccoli', 'Cucumber', 'Potato', 'Tomato']\n",
            "num_classes = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для класифікації зображень була реалізована проста згорткова нейронна мережа з трьома згортковими шарами, що послідовно збільшують кількість каналів з 3 до 64. Після кожного згорткового шару застосовувалась функція активації ReLU та операція підвибірки MaxPooling. Для вирівнювання розмірів використовувався Adaptive Average Pooling. Класифікація здійснювалась за допомогою двох повнозвʼязних шарів із застосуванням Dropout. Для навчання використовувалась функція втрат CrossEntropyLoss та оптимізатор Adam. На вході згорткової мережі використано 3 канали, що відповідає RGB-зображенням. У першому згортковому шарі використано 16 фільтрів для виділення простих ознак, таких як краї та контури. У наступних шарах кількість каналів поступово збільшено до 32 та 64 для витягання більш складних і абстрактних ознак. Розмір ядра 3×3 обрано як стандартний та ефективний для аналізу локальних структур на зображенні.\n",
        "\n"
      ],
      "metadata": {
        "id": "w5XPBBHgmE1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проста CNN (2–3 конв. шари + fully connected)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # conv1: 3 -> 16\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 128x128 -> 64x64\n",
        "\n",
        "            # conv2: 16 -> 32\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 64x64 -> 32x32\n",
        "\n",
        "            # conv3: 32 -> 64\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 32x32 -> 16x16\n",
        "        )\n",
        "\n",
        "        # adaptive pooling, щоб не рахувати розміри вручну\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))  # 64 x 16x16 -> 64 x 4x4\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),               # 64 * 4 * 4 = 1024\n",
        "            nn.Linear(64 * 4 * 4, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "simple_model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_simple = optim.Adam(simple_model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "4otogjXbh6uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Навчання моделі здійснювалось батчами з використанням алгоритму зворотного поширення помилки. Для кожного батча виконувались прямий прохід, обчислення функції втрат, зворотний прохід та оновлення ваг за допомогою оптимізатора Adam. Для оцінки якості моделі на валідаційній та тестовій вибірках використовувався окремий цикл без обчислення градієнтів."
      ],
      "metadata": {
        "id": "6vVBzoVTrxO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Універсальні функції train / evaluate\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "aQcGJJ6xp6L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Навчання моделі здійснювалось протягом 4 епох (зменшено з 10 початкових, бо було перенавчання). Після кожної епохи обчислювались значення функції втрат та точності на тренувальній і валідаційній вибірках. Під час навчання простої згорткової нейронної мережі було досягнуто високої точності вже на перших епохах. Максимальна валідаційна точність 100% була отримана на 4-й епосі. Подальше навчання не призвело до істотного покращення результатів, а незначні коливання точності зумовлені малою кількістю зображень у валідаційній вибірці. Для подальшого аналізу результати зберігались у вигляді історії навчання. Також було виміряно загальний час навчання моделі."
      ],
      "metadata": {
        "id": "C-BLCLWmsgH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Навчання простої CNN\n",
        "num_epochs_simple = 4\n",
        "\n",
        "history_simple = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs_simple):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        simple_model, train_loader_simple, optimizer_simple, criterion, device\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(simple_model, val_loader_simple, criterion, device)\n",
        "\n",
        "    history_simple[\"train_loss\"].append(train_loss)\n",
        "    history_simple[\"train_acc\"].append(train_acc)\n",
        "    history_simple[\"val_loss\"].append(val_loss)\n",
        "    history_simple[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(\n",
        "        f\"[SimpleCNN] Epoch {epoch+1}/{num_epochs_simple} | \"\n",
        "        f\"Train: loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "        f\"Val: loss={val_loss:.4f}, acc={val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "time_simple = time.time() - start_time\n",
        "print(f\"Час навчання SimpleCNN: {time_simple:.1f} с\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qInHp-UXr1RG",
        "outputId": "ae6976d6-59b3-4330-cc71-baf35d6ccafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SimpleCNN] Epoch 1/4 | Train: loss=0.0481, acc=0.9900 | Val: loss=0.0262, acc=0.9938\n",
            "[SimpleCNN] Epoch 2/4 | Train: loss=0.0294, acc=0.9888 | Val: loss=0.0243, acc=0.9938\n",
            "[SimpleCNN] Epoch 3/4 | Train: loss=0.0822, acc=0.9712 | Val: loss=0.1072, acc=0.9625\n",
            "[SimpleCNN] Epoch 4/4 | Train: loss=0.0752, acc=0.9762 | Val: loss=0.0210, acc=1.0000\n",
            "Час навчання SimpleCNN: 47.1 с\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ми використовуємо вже готову, попередньо навчену на ImageNet модель ResNet18 як екстрактор ознак, заморожуємо всі її шари, замінюємо лише останній класифікаційний шар під кількість власних класів і навчаємо тільки цей новий шар для розпізнавання овочів."
      ],
      "metadata": {
        "id": "FwWZs0obx-D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестова точність простої CNN - перевіряємо як прауює моделька :)\n",
        "test_loss_simple, test_acc_simple = evaluate(simple_model, test_loader_simple, criterion, device)\n",
        "print(f\"[SimpleCNN] Test: loss={test_loss_simple:.4f}, acc={test_acc_simple:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCU-hckRsqTh",
        "outputId": "640ff817-85dd-4be9-ead5-8855db3281eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SimpleCNN] Test: loss=0.0584, acc=0.9688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для реалізації transfer learning було використано архітектуру ResNet18 з попередньо навченими на датасеті ImageNet вагами. Всі згорткові шари були заморожені, а останній повнозвʼязний шар класифікатора замінено відповідно до кількості класів у задачі. Для навчання нового класифікатора використовувалась функція втрат CrossEntropyLoss та оптимізатор Adam. Ми використовуємо вже готову, попередньо навчену на ImageNet модель ResNet18 як екстрактор ознак, заморожуємо всі її шари, замінюємо лише останній класифікаційний шар під кількість власних класів і навчаємо тільки цей новий шар для розпізнавання овочів."
      ],
      "metadata": {
        "id": "mCGisLTCxCaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Завантаження ResNet18 + заморозка фіч\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Заморожуємо всі шари, крім останнього\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Замінюємо класифікатор під 4 класи\n",
        "in_features = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = optim.Adam(resnet18.fc.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "2XhforfiwsU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Під час навчання ResNet18 було виконано донавчання (transfer learning): всі згорткові шари були заморожені, а навчання здійснювалось лише для нового класифікаційного шару, який був адаптований під 4 класи овочів."
      ],
      "metadata": {
        "id": "JFkAxfq2yeer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaders для ResNet18\n",
        "train_dataset_resnet = datasets.ImageFolder(\n",
        "    train_dir,\n",
        "    transform=resnet_transform_train\n",
        ")\n",
        "\n",
        "val_dataset_resnet = datasets.ImageFolder(\n",
        "    val_dir,\n",
        "    transform=resnet_transform_eval\n",
        ")\n",
        "\n",
        "test_dataset_resnet = datasets.ImageFolder(\n",
        "    test_dir,\n",
        "    transform=resnet_transform_eval\n",
        ")\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader_resnet = DataLoader(\n",
        "    train_dataset_resnet,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader_resnet = DataLoader(\n",
        "    val_dataset_resnet,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader_resnet = DataLoader(\n",
        "    test_dataset_resnet,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Навчання ResNet18\n",
        "num_epochs_resnet = 5  # зазвичай вистачає менше епох\n",
        "\n",
        "history_resnet = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs_resnet):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        resnet18, train_loader_resnet, optimizer_resnet, criterion, device\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(resnet18, val_loader_resnet, criterion, device)\n",
        "\n",
        "    history_resnet[\"train_loss\"].append(train_loss)\n",
        "    history_resnet[\"train_acc\"].append(train_acc)\n",
        "    history_resnet[\"val_loss\"].append(val_loss)\n",
        "    history_resnet[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(\n",
        "        f\"[ResNet18] Epoch {epoch+1}/{num_epochs_resnet} | \"\n",
        "        f\"Train: loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "        f\"Val: loss={val_loss:.4f}, acc={val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "time_resnet = time.time() - start_time\n",
        "print(f\"Час навчання ResNet18: {time_resnet:.1f} с\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "debVe4VryerP",
        "outputId": "4d0a8e3a-8100-4f56-d434-abc5a5aff50d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet18] Epoch 1/5 | Train: loss=0.2499, acc=0.9663 | Val: loss=0.1279, acc=0.9875\n",
            "[ResNet18] Epoch 2/5 | Train: loss=0.1483, acc=0.9900 | Val: loss=0.0824, acc=0.9938\n",
            "[ResNet18] Epoch 3/5 | Train: loss=0.1007, acc=0.9938 | Val: loss=0.0589, acc=0.9938\n",
            "[ResNet18] Epoch 4/5 | Train: loss=0.0811, acc=0.9912 | Val: loss=0.0455, acc=1.0000\n",
            "[ResNet18] Epoch 5/5 | Train: loss=0.0663, acc=0.9938 | Val: loss=0.0388, acc=1.0000\n",
            "Час навчання ResNet18: 450.8 с\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Після завершення навчання модель ResNet18 була протестована на тестовій вибірці, яка не використовувалась під час тренування. Було отримано значення функції втрат та точності, що характеризують узагальнювальну здатність моделі."
      ],
      "metadata": {
        "id": "4AWLsG9-3tFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестова точність ResNet18\n",
        "test_loss_resnet, test_acc_resnet = evaluate(resnet18, test_loader_resnet, criterion, device)\n",
        "print(f\"[ResNet18] Test: loss={test_loss_resnet:.4f}, acc={test_acc_resnet:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPWddNJ71kEw",
        "outputId": "862621fe-83ce-479b-8b5a-6e0cef3c136a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet18] Test: loss=0.0621, acc=0.9938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обидві моделі виконують одну й ту саму задачу багатокласової класифікації зображень. Різниця між ними полягає у способі навчання: SimpleCNN навчалась з нуля на наявних даних, тоді як ResNet18 використовувала попередньо навчені на ImageNet ознаки та донавчалась лише на рівні класифікатора."
      ],
      "metadata": {
        "id": "hkLFlrzw4znQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# порівняння\n",
        "print(\"=== Порівняння моделей ===\")\n",
        "print(f\"SimpleCNN:  val_acc={history_simple['val_acc'][-1]:.4f}, \"\n",
        "      f\"test_acc={test_acc_simple:.4f}, time={time_simple:.1f} c\")\n",
        "\n",
        "print(f\"ResNet18:   val_acc={history_resnet['val_acc'][-1]:.4f}, \"\n",
        "      f\"test_acc={test_acc_resnet:.4f}, time={time_resnet:.1f} c\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0yL5DMF1me2",
        "outputId": "bcf85ea0-d194-4267-b184-0fbba0d6d32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Порівняння моделей ===\n",
            "SimpleCNN:  val_acc=1.0000, test_acc=0.9688, time=47.1 c\n",
            "ResNet18:   val_acc=1.0000, test_acc=0.9938, time=450.8 c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Незважаючи на однакову точність на валідаційній вибірці, тестова точність SimpleCNN виявилась нижчою, ніж у ResNet18. Це пояснюється кращою здатністю попередньо навчених мереж до узагальнення. Також слід враховувати малий розмір тестової вибірки, що призводить до значних коливань метрики навіть при одній помилці.\n",
        "0.9688 ≈ 39 правильних з 40 (1/40≈2.5% помилка, 39 з 40 правильних → 0.975);\n",
        "0.9938 ≈ 40 з 40, але 1 трохи “не вписалась” через округлення батчів"
      ],
      "metadata": {
        "id": "ojT5Zm8a9J21"
      }
    }
  ]
}